{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "# yaml specific\n",
    "import yaml\n",
    "\n",
    "# Data handling\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config variables\n",
    "raw_data_path = \"raw_data\"\n",
    "clean_data_path = \"clean_data\"\n",
    "tournament_name = \"IPL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yaml(path):\n",
    "    \"\"\"\n",
    "    Parses a given yaml file and returns the object\n",
    "    Args:\n",
    "        path - path of the yaml file to be parsed\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as stream:\n",
    "        try:\n",
    "            data = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_matches_raw_data(tournament_name):\n",
    "    \"\"\"\n",
    "        Parses all the matches inside the tournament_name folder and returns a list of dicts\n",
    "        Args:\n",
    "            tournament_name - Name of tournament to be parsed\n",
    "    \"\"\"\n",
    "    \n",
    "    tournament_path = os.path.join(raw_data_path, tournament_name)\n",
    "    match_files = os.listdir(tournament_path)\n",
    "    matches = []\n",
    "    print(f\"Parsing {len(match_files)} matches for {tournament_name}\")\n",
    "    for match_file in tqdm(match_files):\n",
    "        if \".yaml\" not in match_file:\n",
    "            continue\n",
    "        match_path = os.path.join(tournament_path, match_file)\n",
    "        match = parse_yaml(match_path)\n",
    "        matches.append(match)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_possible_name_match(query_name, players_with_same_surname):\n",
    "    \"\"\"\n",
    "    This function does a fuzzy match to find where to insert query_name in the players database. It returns the best matched player_name\n",
    "    Args:\n",
    "        query_name - query name to be checked with\n",
    "        players_with_same_surname - a subset of the players dataframe for checking with the query_name\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(f\"Getting best match for {query_name}\")\n",
    "    \n",
    "    # collecting all capital letters in the name to be stored as initials\n",
    "    initials = [c for c in query_name if c.isupper()]\n",
    "    \n",
    "    # creating a hash map between the player_name and player_full_name for easy access\n",
    "    name_full_name_map = {}\n",
    "    for index, row in players_with_same_surname.iterrows():\n",
    "        name_full_name_map[row[\"player_name\"]] = row[\"player_full_name\"]\n",
    "    \n",
    "    # List of all choices for the fuzzy algorithm to run on. \n",
    "    choices_name = np.array(players_with_same_surname.player_name)\n",
    "    potential_matches = process.extract(query_name, choices_name, processor=None, limit=50)\n",
    "    \n",
    "    # IF no potential match was found, return null string\n",
    "    if len(potential_matches) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    #print(f\"All matches: {potential_matches}\")\n",
    "    top_score = potential_matches[0][1]\n",
    "    best_match = \"\"\n",
    "    for potential_match in potential_matches:\n",
    "        score = potential_match[1]\n",
    "        match_name = potential_match[0]\n",
    "    \n",
    "        # if you get a perfect score, that should definitely be the correct match\n",
    "        if score == 100:\n",
    "            best_match = match_name\n",
    "            break\n",
    "        \n",
    "        # if you dont get a perfect score, check if all the initials are present in the players full name, that should be the best match\n",
    "        initial_bool = []\n",
    "        for initial in initials:\n",
    "            #print(f\"Checking if {initial} is present in {name_full_name_map[match_name]}\")\n",
    "            if initial in name_full_name_map[match_name]:\n",
    "                initial_bool.append(True)\n",
    "            else:\n",
    "                initial_bool.append(False)\n",
    "            name_full_name_map[match_name] = name_full_name_map[match_name].replace(initial, '', 1)\n",
    "\n",
    "        if all(initial_bool):\n",
    "            best_match = match_name\n",
    "            break\n",
    "        \n",
    "        # if either of methods fail, return the best match the fuzzy scoring algo returned\n",
    "        if score > top_score:\n",
    "            top_score = score\n",
    "            best_match = match_name\n",
    "\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_players(update_column, update_value, check_column, check_value):\n",
    "    \"\"\"\n",
    "    This function \n",
    "        - reads the player.csv file\n",
    "        - updates update_column with update_value where check_column is check_value\n",
    "        - writes it back\n",
    "    Args:\n",
    "        query_name - query name to be checked with\n",
    "        players_with_same_surname - a subset of the players dataframe for checking with the query_name\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(f\"Updating {update_column} with {update_value} where {check_column} is {check_value}\")\n",
    "    players = pd.read_csv(os.path.join(clean_data_path, \"player.csv\"))\n",
    "    players = players.loc[:, ~players.columns.str.contains('^Unnamed')]\n",
    "    players.loc[players[check_column] == check_value, update_column] = update_value\n",
    "    #players[update_column] = np.where(players[check_column] == check_value, update_value)\n",
    "    players.to_csv(os.path.join(clean_data_path, \"player.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will be used to curate 2 tables. \n",
    "## 1) Match 2) Ball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/818 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 818 matches for IPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 818/818 [03:11<00:00,  4.27it/s]\n"
     ]
    }
   ],
   "source": [
    "matches = get_all_matches_raw_data(tournament_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to first match all player names found in this dataset to the player_ids we have. Our player table contains full names (eg: David Warner) while this dataset has only the short names typically used in score cards (eg. DA Warner). So using a combination of fuzzy and boolean matching to map these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_csv(os.path.join(clean_data_path, \"player.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a unique player names set with information from each ball of all the 817 IPL matches. Considering batsman bowler and non-striker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 816/816 [00:00<00:00, 4152.47it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_player_names = set()\n",
    "for match in tqdm(matches):\n",
    "    for inning in match['innings']:\n",
    "        for inning_number in inning:\n",
    "            for ball in inning[inning_number]['deliveries']:\n",
    "                for ball_number in ball:\n",
    "                    unique_player_names.add(ball[ball_number]['batsman'])\n",
    "                    unique_player_names.add(ball[ball_number]['bowler'])\n",
    "                    unique_player_names.add(ball[ball_number]['non_striker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_player_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for each one of these unique players, we are trying to find a best match map from the players sheet and updating the player_display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████                                                                | 116/580 [00:06<00:25, 18.46it/s]C:\\Users\\aniru\\miniconda3\\envs\\torch\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 580/580 [00:29<00:00, 19.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for player_name in tqdm(unique_player_names):\n",
    "    players_with_same_surname = players[players.player_name.str.contains(player_name.split(\" \")[-1])]\n",
    "    best_match_name = get_best_possible_name_match(player_name, players_with_same_surname)\n",
    "    # if null string was returned, skip the player\n",
    "    if best_match_name:\n",
    "        update_players(\"player_display_name\", player_name, \"player_name\", best_match_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond this if we find any inaccuracies in the mapping, lets just manually correct them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
