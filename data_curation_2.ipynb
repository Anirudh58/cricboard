{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "# yaml specific\n",
    "import yaml\n",
    "\n",
    "# Data handling\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# my library\n",
    "from db_utils import update_player, add_player "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config variables\n",
    "raw_data_path = \"raw_data\"\n",
    "clean_data_path = \"clean_data\"\n",
    "tournament_name = \"IPL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_players_not_mapped(matches):\n",
    "    \"\"\"\n",
    "    Utility function to quickly run through all deliveries of every match and see if there is any exception coming (if there is any player unmapped)\n",
    "    Args:\n",
    "        matches - a list of match objects parsed from the yaml files\n",
    "    \"\"\"\n",
    "    players_not_found_or_mapped = []\n",
    "    for match in tqdm(matches):\n",
    "        try:\n",
    "            for inning in match['innings']:\n",
    "                for inning_number in inning:\n",
    "                    for ball in inning[inning_number]['deliveries']:\n",
    "                        for ball_number in ball:\n",
    "\n",
    "                            batsman = player_id_map[ball[ball_number]['batsman']]\n",
    "                            bowler = player_id_map[ball[ball_number]['bowler']]\n",
    "                            non_striker = player_id_map[ball[ball_number]['non_striker']]\n",
    "\n",
    "                            if \"wicket\" in ball[ball_number]:\n",
    "                                player_dismissed = player_id_map[ball[ball_number][\"wicket\"][\"player_out\"]]\n",
    "                                dismissal_type = ball[ball_number][\"wicket\"][\"kind\"]\n",
    "\n",
    "                                if \"fielders\" in ball[ball_number][\"wicket\"]:\n",
    "                                    # There is \"(sub)\" when a substitute fielder is involved in a wicket\n",
    "                                    fielders = \",\".join([str(player_id_map[fielder.replace(\" (sub)\", \"\")]) for fielder in ball[ball_number][\"wicket\"][\"fielders\"]])\n",
    "        except Exception as e:\n",
    "            print(f\"Exception {e} happened in ball number {ball_number} \")\n",
    "            print(f\"ball {ball[ball_number]}\")\n",
    "            print(f\"match info: {match['info']}\")\n",
    "            players_not_found_or_mapped.append(e.args[0])\n",
    "            \n",
    "    return players_not_found_or_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yaml(path):\n",
    "    \"\"\"\n",
    "    Parses a given yaml file and returns the object\n",
    "    Args:\n",
    "        path - path of the yaml file to be parsed\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as stream:\n",
    "        try:\n",
    "            data = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_matches_raw_data(tournament_name):\n",
    "    \"\"\"\n",
    "        Parses all the matches inside the tournament_name folder and returns a list of dicts\n",
    "        Args:\n",
    "            tournament_name - Name of tournament to be parsed\n",
    "    \"\"\"\n",
    "    \n",
    "    tournament_path = os.path.join(raw_data_path, tournament_name)\n",
    "    match_files = os.listdir(tournament_path)\n",
    "    matches = []\n",
    "    print(f\"Parsing {len(match_files)} matches for {tournament_name}\")\n",
    "    for match_file in tqdm(match_files):\n",
    "        if \".yaml\" not in match_file:\n",
    "            continue\n",
    "        match_path = os.path.join(tournament_path, match_file)\n",
    "        match = parse_yaml(match_path)\n",
    "        matches.append(match)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_possible_name_match(query_name, players_with_same_surname):\n",
    "    \"\"\"\n",
    "    This function does a fuzzy match to find where to insert query_name in the players database. It returns the best matched player_name\n",
    "    Args:\n",
    "        query_name - query name to be checked with\n",
    "        players_with_same_surname - a subset of the players dataframe for checking with the query_name\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(f\"Getting best match for {query_name}\")\n",
    "    \n",
    "    # collecting all capital letters in the name to be stored as initials\n",
    "    initials = [c for c in query_name if c.isupper()]\n",
    "    \n",
    "    # creating a hash map between the player_name and player_full_name for easy access\n",
    "    name_full_name_map = {}\n",
    "    for index, row in players_with_same_surname.iterrows():\n",
    "        name_full_name_map[row[\"player_name\"]] = row[\"player_full_name\"]\n",
    "    \n",
    "    # List of all choices for the fuzzy algorithm to run on. \n",
    "    choices_name = np.array(players_with_same_surname.player_name)\n",
    "    potential_matches = process.extract(query_name, choices_name, processor=None, limit=50)\n",
    "    \n",
    "    # IF no potential match was found, return null string\n",
    "    if len(potential_matches) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    #print(f\"All matches: {potential_matches}\")\n",
    "    top_score = potential_matches[0][1]\n",
    "    best_match = \"\"\n",
    "    for potential_match in potential_matches:\n",
    "        score = potential_match[1]\n",
    "        match_name = potential_match[0]\n",
    "    \n",
    "        # if you get a perfect score, that should definitely be the correct match\n",
    "        if score == 100:\n",
    "            best_match = match_name\n",
    "            break\n",
    "        \n",
    "        # if you dont get a perfect score, check if all the initials are present in the players full name, that should be the best match\n",
    "        initial_bool = []\n",
    "        for initial in initials:\n",
    "            #print(f\"Checking if {initial} is present in {name_full_name_map[match_name]}\")\n",
    "            if initial in name_full_name_map[match_name]:\n",
    "                initial_bool.append(True)\n",
    "            else:\n",
    "                initial_bool.append(False)\n",
    "            name_full_name_map[match_name] = name_full_name_map[match_name].replace(initial, '', 1)\n",
    "\n",
    "        if all(initial_bool):\n",
    "            best_match = match_name\n",
    "            break\n",
    "        \n",
    "        # if either of methods fail, return the best match the fuzzy scoring algo returned\n",
    "        if score > top_score:\n",
    "            top_score = score\n",
    "            best_match = match_name\n",
    "\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will be used to curate 3 tables. \n",
    "## 1) Venue 2) Match 3) Ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                               | 0/818 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 818 matches for IPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 818/818 [03:47<00:00,  3.60it/s]\n"
     ]
    }
   ],
   "source": [
    "matches = get_all_matches_raw_data(tournament_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to first match all player names found in this dataset to the player_ids we have. Our player table contains full names (eg: David Warner) while this dataset has only the short names typically used in score cards (eg. DA Warner). So using a combination of fuzzy and boolean matching to map these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_csv(os.path.join(clean_data_path, \"player.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a unique player names set with information from each ball of all the 817 IPL matches. Considering batsman bowler and non-striker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 816/816 [00:00<00:00, 3685.57it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_player_names = set()\n",
    "for match in tqdm(matches):\n",
    "    for inning in match['innings']:\n",
    "        for inning_number in inning:\n",
    "            for ball in inning[inning_number]['deliveries']:\n",
    "                for ball_number in ball:\n",
    "                    unique_player_names.add(ball[ball_number]['batsman'])\n",
    "                    unique_player_names.add(ball[ball_number]['bowler'])\n",
    "                    unique_player_names.add(ball[ball_number]['non_striker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_player_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for each one of these unique players, we are trying to find a best match map from the players sheet and updating the player_display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                                              | 255/580 [00:14<00:18, 18.01it/s]C:\\Users\\aniru\\miniconda3\\envs\\torch\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 580/580 [00:32<00:00, 17.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for player_name in tqdm(unique_player_names):\n",
    "    players_with_same_surname = players[players.player_name.str.contains(player_name.split(\" \")[-1])]\n",
    "    best_match_name = get_best_possible_name_match(player_name, players_with_same_surname)\n",
    "    # if null string was returned, skip the player\n",
    "    if best_match_name:\n",
    "        update_player(\"player_display_name\", player_name, \"player_name\", best_match_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond this if we find any inaccuracies in the mapping, lets just manually correct them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Venue table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 816/816 [00:00<00:00, 819576.64it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_venues = set()\n",
    "all_venues = []\n",
    "for match in tqdm(matches):\n",
    "    unique_venues.add(match['info']['venue'])\n",
    "    all_venues.append(match['info']['venue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to find if there are duplicate names for the same stadium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_venues_list = list(unique_venues)\n",
    "similarity_scores = []\n",
    "for i in range(len(unique_venues_list)-1):\n",
    "    for j in range(i+1, len(unique_venues_list)):\n",
    "        similarity_score = fuzz.WRatio(unique_venues_list[i], unique_venues_list[j])\n",
    "        similarity_scores.append([i, j, similarity_score])\n",
    "\n",
    "similarity_scores_sorted = sorted(similarity_scores, key=lambda x : x[2], reverse=True)\n",
    "counter = 0\n",
    "for pair in similarity_scores_sorted:\n",
    "    #print(f\"{unique_venues_list[pair[0]]} - {unique_venues_list[pair[1]]} --> {pair[2]}\")\n",
    "    if counter > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These stadiums have duplicates so removing them, but they need to be mapped to the same venue_id when iterating over the matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_venues_list.remove(\"M.Chinnaswamy Stadium\")\n",
    "unique_venues_list.remove(\"Punjab Cricket Association IS Bindra Stadium, Mohali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_columns = [\"venue_id\", \"venue_name\"]\n",
    "venue_csv = pd.DataFrame(columns = venue_columns)\n",
    "for i in range(len(unique_venues_list)):\n",
    "    venue_id = i+1\n",
    "    venue_name = unique_venues_list[i]\n",
    "    venue_csv = venue_csv.append({\"venue_id\" : venue_id, \n",
    "                                  \"venue_name\" : venue_name}, ignore_index=True)\n",
    "venue_csv.to_csv(os.path.join(clean_data_path, \"venue.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility maps for tournaments, venues, teams and players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tournament = pd.read_csv(os.path.join(clean_data_path, \"tournament.csv\"))\n",
    "df_tournament = df_tournament.loc[:, ~df_tournament.columns.str.contains('^Unnamed')]\n",
    "tournament_id_map = dict(zip(df_tournament.tournament_name, df_tournament.tournament_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venue = pd.read_csv(os.path.join(clean_data_path, \"venue.csv\"))\n",
    "df_venue = df_venue.loc[:, ~df_venue.columns.str.contains('^Unnamed')]\n",
    "venue_id_map = dict(zip(df_venue.venue_name, df_venue.venue_id))\n",
    "\n",
    "# Mapping the duplicates as well to its correct venue ids\n",
    "venue_id_map[\"Punjab Cricket Association IS Bindra Stadium, Mohali\"] = venue_id_map[\"Punjab Cricket Association Stadium, Mohali\"]\n",
    "venue_id_map[\"M.Chinnaswamy Stadium\"] = venue_id_map[\"M Chinnaswamy Stadium\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team = pd.read_csv(os.path.join(clean_data_path, \"team.csv\"))\n",
    "df_team = df_team.loc[:, ~df_team.columns.str.contains('^Unnamed')]\n",
    "team_id_map = dict(zip(df_team.team_name, df_team.team_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this cell for all manual corrections to update/insert in players table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updates\n",
    "update_player(\"player_display_name\", \"RG Sharma\", \"player_name\", \"Rohit Sharma\")\n",
    "update_player(\"player_display_name\", \"SA Yadav\", \"player_name\", \"Suryakumar Yadav\")\n",
    "update_player(\"player_display_name\", \"CRD Fernando\", \"player_name\", \"Dilhara Fernando\")\n",
    "update_player(\"player_display_name\", \"DPMD Jayawardene\", \"player_name\", \"Mahela Jayawardene\")\n",
    "update_player(\"player_display_name\", \"R Powell\", \"player_name\", \"Rovman Powell\")\n",
    "update_player(\"player_display_name\", \"RK Singh\", \"player_name\", \"Rinku Singh\")\n",
    "update_player(\"player_display_name\", \"JPR Scantlebury-Searles\", \"player_name\", \"Javon Searles\")\n",
    "update_player(\"player_display_name\", \"Milind Kumar\", \"player_name\", \"Milind Kumar\")\n",
    "update_player(\"player_display_name\", \"NB Singh\", \"player_name\", \"Nathu Singh\")\n",
    "update_player(\"player_display_name\", \"AS Yadav\", \"player_name\", \"Arjun Yadav\")\n",
    "update_player(\"player_display_name\", \"VRV Singh\", \"player_full_name\", \"Vikram Raj Vir Singh\")\n",
    "update_player(\"player_display_name\", \"R Bishnoi\", \"player_full_name\", \"Rajesh Bishnoi\")\n",
    "update_player(\"player_display_name\", \"KH Devdhar\", \"player_full_name\", \"Kedar Hemant Devdhar\")\n",
    "update_player(\"player_display_name\", \"Harmeet Singh (2)\", \"player_full_name\", \"Harmeet Singh\")\n",
    "update_player(\"player_display_name\", \"AV Wankhade\", \"player_full_name\", \"Apoorv Vijay Wankhade\")\n",
    "update_player(\"player_display_name\", \"B Aparajith\", \"player_full_name\", \"Baba Aparajith\")\n",
    "update_player(\"player_display_name\", \"Anmolpreet Singh\", \"player_full_name\", \"Anmolpreet Singh\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# inserts\n",
    "add_player(\"Ankit Soni\", \"Ankit Soni\", \"Ankit Soni\", \"Right-hand bat\", \"Legbreak googly\", \"02/08/1993\", \"2\", str(team_id_map[\"Gujarat Lions\"]))\n",
    "add_player(\"J Suchith\", \"Jagadeesha Suchith\", \"Jagadeesha Suchith\", \"Left-hand bat\", \"Slow left-arm orthodox\", \"01/16/1994\", \"2\", str(team_id_map[\"Kings XI Punjab\"]))\n",
    "add_player(\"SD Lad\", \"Siddhesh Lad\", \"Siddhesh Dinesh Lad\", \"Right-hand bat\", \"Right-arm offbreak\", \"23/05/92\", \"2\", str(team_id_map[\"Mumbai Indians\"]))\n",
    "add_player(\"S Kaushik\", \"Shivil Kaushik\", \"Shivil Sharma Kaushik\", \"Left-hand bat\", \"Slow left-arm wrist-spin\", \"07/09/95\", \"2\", str(team_id_map[\"Gujarat Lions\"]))\n",
    "add_player(\"KM Asif\", \"KM Asif\", \"KM Asif\", \"Right-hand bat\", \"Right-arm medium\", \"24/07/93\", \"2\", str(team_id_map[\"Chennai Super Kings\"]))\n",
    "add_player(\"AS Roy\", \"Anukul Roy\", \"Anukul Sudhakar Roy\", \"Left-hand bat\", \"Slow left-arm orthodox\", \"30/11/98\", \"2\", str(team_id_map[\"Mumbai Indians\"]))\n",
    "add_player(\"YBK Jaiswal\", \"Yashasvi Jaiswal\", \"Yashasvi Bhupendra Kumar Jaiswal\", \"Left-hand bat\", \"\", \"28/12/01\", \"2\", str(team_id_map[\"Rajasthan Royals\"]))\n",
    "add_player(\"Abdul Samad\", \"Abdul Samad\", \"Abdul Samad\", \"Right-hand bat\", \"Right-arm legbreak\", \"10/28/01\", \"2\", str(team_id_map[\"Sunrisers Hyderabad\"]))\n",
    "add_player(\"Kartik Tyagi\", \"Kartik Tyagi\", \"Kartik Tyagi\", \"Right-hand bat\", \"Right-arm fast\", \"11/08/00\", \"2\", str(team_id_map[\"Rajasthan Royals\"]))\n",
    "add_player(\"Lalit Yadav\", \"Lalit Yadav\", \"Lalit Yadav\", \"Right-hand bat\", \"Right-arm offbreak\", \"03/01/97\", \"2\", str(team_id_map[\"Delhi Daredevils\"]))\n",
    "add_player(\"Ravi Bishnoi\", \"Ravi Bishnoi\", \"Ravi Bishnoi\", \"Right-hand bat\", \"Legbreak googly\", \"05/09/00\", \"2\", str(team_id_map[\"Kings XI Punjab\"]))\n",
    "add_player(\"RA Shaikh\", \"Rahil Shaikh\", \"Rahil Akhil Ahmed Shaikh\", \"Left-hand bat\", \"Left-arm medium\", \"12/06/85\", \"2\", str(team_id_map[\"Mumbai Indians\"]))\n",
    "add_player(\"AN Ahmed\", \"AN Ahmed\", \"AN Ahmed\", \"Left-hand bat\", \"Left-arm medium\", \"12/06/85\", \"2\", str(team_id_map[\"Mumbai Indians\"]))\n",
    "add_player(\"AA Kazi\", \"Abrar Kazi\", \"Abrar Anjum Kazi\", \"Left-hand bat\", \"Slow left-arm orthodox\", \"10/29/89\", \"2\", str(team_id_map[\"Royal Challengers Bangalore\"]))\n",
    "add_player(\"T Mishra\", \"Tanmay Mishra\", \"Tanmay Mishra\", \"Right-hand bat\", \"Right-arm medium-fast\", \"12/22/86\", \"2\", str(team_id_map[\"Deccan Chargers\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player = pd.read_csv(os.path.join(clean_data_path, \"player.csv\"))\n",
    "df_player = df_player.loc[:, ~df_player.columns.str.contains('^Unnamed')]\n",
    "player_id_map = dict(zip(df_player.player_display_name, df_player.player_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match and Ball table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 816/816 [01:19<00:00, 10.31it/s]\n"
     ]
    }
   ],
   "source": [
    "match_columns = [\"match_id\", \"tournament_id\", \"venue_id\", \"match_date\", \"team_1\", \"team_2\", \"toss_winner\", \"toss_decision\", \"player_of_match\", \n",
    "                 \"match_winner\", \"match_win_by_runs\", \"match_win_by_wickets\", \"highlights_url\", \"match_url\", \"match_description\"]\n",
    "#match_csv = pd.DataFrame(columns = match_columns)\n",
    "\n",
    "ball_columns = [\"ball_id\", \"match_id\", \"ball_number\", \"innings_number\", \"batsman\", \"bowler\", \"non_striker\", \"batsman_runs\", \"wide_runs\", \"noball_runs\",\n",
    "                \"bye_runs\", \"legbye_runs\", \"extras_runs\", \"total_runs\", \"player_dismissed\", \"dismissal_type\", \"fielders\", \"ball_description\", \"ball_url\"]\n",
    "#ball_csv = pd.DataFrame(columns = ball_columns)\n",
    "\n",
    "match_csv = {}\n",
    "ball_csv = {}\n",
    "\n",
    "i = 0 # match id\n",
    "j = 0 # ball id\n",
    "for match in tqdm((matches), position=0, leave=True):\n",
    "    \n",
    "    # First adding entries to the match table\n",
    "    try:\n",
    "        \n",
    "        match_id = i\n",
    "        tournament_id = tournament_id_map[match['info']['competition']] # For ODI, TEST \"competition\" to be changed to \"match_Type\"\n",
    "        venue_id = venue_id_map[match['info']['venue']]\n",
    "        \n",
    "        # if date is a date instance, parse and read. if not directly read\n",
    "        match_date = [\",\".join([str(date.strftime('%Y-%m-%d')) if isinstance(date, datetime.date) else str(date) for date in match['info']['dates']])]\n",
    "\n",
    "        team_1_best_fuzzy_match = process.extractOne(match['info']['teams'][0], team_id_map.keys())[0]\n",
    "        team_2_best_fuzzy_match = process.extractOne(match['info']['teams'][1], team_id_map.keys())[0]\n",
    "        team_1 = team_id_map[team_1_best_fuzzy_match]\n",
    "        team_2 = team_id_map[team_2_best_fuzzy_match]\n",
    "\n",
    "        toss_winner_best_fuzzy_match = process.extractOne(match['info']['toss']['winner'], team_id_map.keys())[0]\n",
    "        toss_winner = team_id_map[toss_winner_best_fuzzy_match]\n",
    "        toss_decision = match['info']['toss']['decision']\n",
    "        \n",
    "        # Match was canceled/washed out\n",
    "        if \"result\" in match['info']['outcome'] and match['info']['outcome']['result'] == \"no result\":\n",
    "            match_winner = \"NA\"\n",
    "            match_win_by_wickets = \"NA\"\n",
    "            match_win_by_runs = \"NA\"\n",
    "            player_of_match = \"NA\"\n",
    "            \n",
    "        # Match was tied\n",
    "        elif \"result\" in match['info']['outcome'] and match['info']['outcome']['result'] == \"tie\":\n",
    "            match_winner = \"TIE\"\n",
    "            match_win_by_wickets = \"NA\"\n",
    "            match_win_by_runs = \"NA\"\n",
    "            player_of_match = \",\".join([str(player_id_map[player]) for player in match['info']['player_of_match']])\n",
    "\n",
    "        elif \"runs\" in match['info']['outcome']['by']:\n",
    "            match_win_by_runs = match['info']['outcome']['by']['runs']\n",
    "            match_win_by_wickets = 'NA'\n",
    "            match_winner_best_fuzzy_match = process.extractOne(match['info']['outcome']['winner'], team_id_map.keys())[0]\n",
    "            match_winner = team_id_map[match_winner_best_fuzzy_match]\n",
    "            player_of_match = \",\".join([str(player_id_map[player]) for player in match['info']['player_of_match']])\n",
    "\n",
    "        elif \"wickets\" in match['info']['outcome']['by']:\n",
    "            match_win_by_wickets = match['info']['outcome']['by']['wickets']\n",
    "            match_win_by_runs = 'NA'\n",
    "            match_winner_best_fuzzy_match = process.extractOne(match['info']['outcome']['winner'], team_id_map.keys())[0]\n",
    "            match_winner = team_id_map[match_winner_best_fuzzy_match]\n",
    "            player_of_match = \",\".join([str(player_id_map[player]) for player in match['info']['player_of_match']])\n",
    "        \n",
    "        # For ambitious future deep learning projects\n",
    "        highlights_url = 'NA'\n",
    "        match_url = 'NA'\n",
    "        match_description = 'NA'\n",
    "        \n",
    "        match_csv[i] = {\n",
    "                        \"match_id\" : match_id, \n",
    "                        \"tournament_id\" : tournament_id,\n",
    "                        \"venue_id\" : venue_id,\n",
    "                        \"match_date\" : match_date, \n",
    "                        \"team_1\" : team_1,\n",
    "                        \"team_2\" : team_2,\n",
    "                        \"toss_winner\" : toss_winner,\n",
    "                        \"toss_decision\" : toss_decision,\n",
    "                        \"player_of_match\" : player_of_match,\n",
    "                        \"match_winner\" : match_winner,\n",
    "                        \"match_win_by_runs\" : match_win_by_runs,\n",
    "                        \"match_win_by_wickets\" : match_win_by_wickets,\n",
    "                        \"highlights_url\" : highlights_url,\n",
    "                        \"match_url\" : match_url,\n",
    "                        \"match_description\" : match_description\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        \n",
    "        print(\"Exception happened in match: \", e)\n",
    "        print(match['info'])\n",
    "        \n",
    "        break\n",
    "    \n",
    "    \n",
    "    # Then adding entries to the ball table\n",
    "    \n",
    "    try:\n",
    "        for inning in match['innings']:\n",
    "            for inning_number in inning:\n",
    "                for ball in inning[inning_number]['deliveries']:\n",
    "                    for ball_number in ball:\n",
    "                        ball_id = j\n",
    "                        innings_number = inning_number[0]\n",
    "                        batsman = player_id_map[ball[ball_number]['batsman']]\n",
    "                        bowler = player_id_map[ball[ball_number]['bowler']]\n",
    "                        non_striker = player_id_map[ball[ball_number]['non_striker']]\n",
    "                        \n",
    "                        wide_runs = 0\n",
    "                        bye_runs = 0\n",
    "                        noball_runs = 0\n",
    "                        legbye_runs = 0\n",
    "                        batsman_runs = 0\n",
    "                        extras_runs = 0\n",
    "                        total_runs = 0\n",
    "                        \n",
    "                        player_dismissed = \"NA\"\n",
    "                        dismissal_type = \"NA\"\n",
    "                        fielders = \"NA\"\n",
    "                        \n",
    "                        if \"extras\" in ball[ball_number]:\n",
    "                            if \"wides\" in ball[ball_number][\"extras\"]:\n",
    "                                wide_runs = ball[ball_number][\"extras\"][\"wides\"]\n",
    "                            if \"legbyes\" in ball[ball_number][\"extras\"]:\n",
    "                                legbye_runs = ball[ball_number][\"extras\"][\"legbyes\"]\n",
    "                            if \"noballs\" in ball[ball_number][\"extras\"]:\n",
    "                                noball_runs = ball[ball_number][\"extras\"][\"noballs\"]\n",
    "                            if \"byes\" in ball[ball_number][\"extras\"]:\n",
    "                                bye_runs = ball[ball_number][\"extras\"][\"byes\"]\n",
    "                        \n",
    "                        if \"runs\" in ball[ball_number]:\n",
    "                            batsman_runs = ball[ball_number][\"runs\"][\"batsman\"]\n",
    "                            extras_runs = ball[ball_number][\"runs\"][\"extras\"]\n",
    "                            total_runs = ball[ball_number][\"runs\"][\"total\"]\n",
    "                            \n",
    "                        if \"wicket\" in ball[ball_number]:\n",
    "                            player_dismissed = player_id_map[ball[ball_number][\"wicket\"][\"player_out\"]]\n",
    "                            dismissal_type = ball[ball_number][\"wicket\"][\"kind\"]\n",
    "                            \n",
    "                            if \"fielders\" in ball[ball_number][\"wicket\"]:\n",
    "                                # There is \"(sub)\" when a substitute fielder is involved in a wicket\n",
    "                                fielders = \",\".join([str(player_id_map[fielder.replace(\" (sub)\", \"\")]) for fielder in ball[ball_number][\"wicket\"][\"fielders\"]])\n",
    "                        \n",
    "                        # For ambitious future deep learning projects\n",
    "                        ball_description = \"NA\"\n",
    "                        ball_url = \"NA\"\n",
    "                        \n",
    "                        ball_csv[j] = {\n",
    "                                        \"ball_id\" : j, \n",
    "                                        \"match_id\" : match_id,\n",
    "                                        \"ball_number\" : ball_number,\n",
    "                                        \"innings_number\" : innings_number, \n",
    "                                        \"batsman\" : batsman,\n",
    "                                        \"bowler\" : bowler,\n",
    "                                        \"non_striker\" : non_striker,\n",
    "                                        \"batsman_runs\" : batsman_runs,\n",
    "                                        \"wide_runs\" : wide_runs,\n",
    "                                        \"bye_runs\" : bye_runs,\n",
    "                                        \"noball_runs\" : noball_runs,\n",
    "                                        \"legbye_runs\" : legbye_runs,\n",
    "                                        \"extras_runs\" : extras_runs,\n",
    "                                        \"total_runs\" : total_runs,\n",
    "                                        \"player_dismissed\" : player_dismissed,\n",
    "                                        \"dismissal_type\" : dismissal_type,\n",
    "                                        \"fielders\" : fielders,\n",
    "                                        \"ball_description\" : ball_description,\n",
    "                                        \"ball_url\" : ball_url,\n",
    "                        }\n",
    "                        \n",
    "                        j += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} happened in ball number {ball_number} \")\n",
    "        print(f\"ball {ball[ball_number]}\")\n",
    "        print(f\"match info: {match['info']}\")\n",
    "        break\n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_csv = pd.DataFrame.from_dict(match_csv, \"index\")\n",
    "df_ball_csv = pd.DataFrame.from_dict(ball_csv, \"index\")\n",
    "\n",
    "df_match_csv.to_csv(os.path.join(clean_data_path, \"match.csv\"), index=False)\n",
    "df_ball_csv.to_csv(os.path.join(clean_data_path, \"ball.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
